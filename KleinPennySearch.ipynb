{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfeb774-ab1c-486f-960f-8df26a30589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Importing requests, BeautifulSoup for scraping property site\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Importing necessary langchain modules\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Importing langsmith Client for communication\n",
    "from langsmith import Client\n",
    "\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f531d0-36a7-4f09-848c-12096a2032d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting main listing page\n",
    "url = \"https://kleinpennyrentals.com/list\"\n",
    "propertyListingPage = requests.get(url)\n",
    "propertyListingSoup = BeautifulSoup(propertyListingPage.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d825757-df60-48fd-9fae-d03dd1b4b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "propertyLinks = []\n",
    "\n",
    "# Getting all properties in the main listing page\n",
    "properties = propertyListingSoup.find_all(\"td\", {\"class\": \"views-field-title\"})\n",
    "\n",
    "baseURL = \"https://kleinpennyrentals.com\"\n",
    "# Looping through to get each property link\n",
    "for property in properties:\n",
    "  link = property.find_all(\"a\")[0][\"href\"]\n",
    "  propertyLinks.append(baseURL + link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27314208-ab1b-40fc-8aa1-091772fec592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n",
      " ········\n",
      " ········\n"
     ]
    }
   ],
   "source": [
    "# Setting up OpenAPI key, PineCone API, LangChain API\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "os.environ['PINECONE_API_KEY'] = getpass.getpass()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass() \n",
    "\n",
    "# Choosing llm model --> using 4o-mini \n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc74b52-6db7-4104-88a7-314c42d1a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the property sites\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=propertyLinks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26970c45-325b-4fd9-9a3d-7e8e359d2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pinecone index --> not necessary now\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_index = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "\n",
    "index_name = \"klein-penny-index\"\n",
    "\n",
    "# pinecone_index.create_index(\n",
    "#     name=index_name,\n",
    "#     dimension=1536, # Replace with your model dimensions\n",
    "#     metric=\"cosine\", # Replace with your model metric\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud=\"aws\",\n",
    "#         region=\"us-east-1\"\n",
    "#     ) \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de367cd9-791c-4924-a9f0-79a2f7fd46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c17a8b7-9255-44a0-9ca8-62d307db33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the text and creating the vector store with PineCone\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "# vectorstore = PineconeVectorStore(index_name=index_name, embedding=OpenAIEmbeddings())\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "        splits,\n",
    "        index_name=index_name,\n",
    "        embedding=OpenAIEmbeddings()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7520a2c5-2f42-4038-be91-2caf121aa56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "875b115f-3cd8-472f-a2ef-26a16eeca3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229ae28c-885c-424b-a66b-9bde241047c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "# retriever = vectorstore.as_retriever()\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 5, \"lambda_mult\": 0.5},\n",
    ")\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db98ab7-3377-40a7-b2b1-9600d88d84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using custom prompt to get property info\n",
    "system_prompt = (\n",
    "    \"You are given a list of documents (each associated with a property) and their associated descriptions, titles, and other information as context. \"\n",
    "    \"Use the following pieces of retrieved context to give properties that match the user's question.\"\n",
    "    \"If you don't know the answer, say that you \"\n",
    "    \"don't know. If you use any information from the context, list its metadata in your answer.\" \n",
    "    \"\"\n",
    "    \"\\n\\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating chain so we can grab source from context\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e80cc41-8da1-43a5-a26d-637fc1603416",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Help me find an apartment with a cast-iron and porcelain Kohler tub\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e4cadf0-68b4-4ae4-a4b6-5946d515ecad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found a couple of apartments that feature a cast-iron and porcelain Kohler tub:\n",
      "\n",
      "1. **20 N Congress, Apt 5**\n",
      "   - **Bedrooms:** 4\n",
      "   - **Bathrooms:** 4\n",
      "   - **Price:** $700 per bedroom per month\n",
      "   - **Available:** May 2026\n",
      "   - **Description:** Each bedroom has its own private bath featuring ceramic tile floors and tub surround, including a Kohler cast iron porcelain tub.\n",
      "   - **Amenities:** 5 person hot tub, central air conditioning, hardwood floors, large closets, laundry room, dishwasher, and more.\n",
      "   - **Security Deposit:** $700 per person\n",
      "   - **Metadata:** 20 N Congress St Apt 5\n",
      "\n",
      "2. **20 N Congress, Apt 4**\n",
      "   - **Bedrooms:** 4\n",
      "   - **Bathrooms:** 4\n",
      "   - **Price:** $700 per bedroom per month\n",
      "   - **Available:** May 2026\n",
      "   - **Description:** Each bedroom has a private bathroom with ceramic tile floor and tub surround, and a Kohler cast iron porcelain tub.\n",
      "   - **Amenities:** 5 person hot tub, central air conditioning, hardwood floors, laundry room, dishwasher, and more.\n",
      "   - **Security Deposit:** $700 per person\n",
      "   - **Metadata:** 20 N Congress St Apt 4\n",
      "\n",
      "If you would like more information about these apartments or want to inquire further, please let me know!\n",
      "\n",
      "\n",
      "You can check out more related properties here: \n",
      "20 N Congress, Apt 2: 7 Bed, 7 Bath Rental in Uptown Athens: https://kleinpennyrentals.com/athens-ohio-housing/20-n-congress-st-apt-2\n",
      "74 E State, Apt 6: 2 Beds, 1 Block to Uptown, New Bathroom: https://kleinpennyrentals.com/athens-ohio-housing/74-e-state-st-apt-6\n",
      "20 N Congress, Apt 5: 4 Bed, 4 Bath Rental Close to OU: https://kleinpennyrentals.com/athens-ohio-housing/20-n-congress-st-apt-5\n",
      "20 N Congress, Apr 4: Best 3 Bed, 2 Bath Apartment in Athens: https://kleinpennyrentals.com/athens-ohio-housing/20-n-congress-st-apt-4\n",
      "20 N Congress, Apt 4: 5 Bed, 5 Bath Luxury Uptown OU Apt: https://kleinpennyrentals.com/athens-ohio-housing/20-n-congress-st-apt-7\n"
     ]
    }
   ],
   "source": [
    "print(response[\"answer\"])\n",
    "# response[\"context\"][0]\n",
    "print(\"\\n\\nYou can check out more related properties here: \")\n",
    "for found in response[\"context\"]:\n",
    "    print(found.metadata[\"title\"] + \": \" + found.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00beb55a-9edb-4edf-a084-a3cf014f07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of testing for model\n",
    "import deepeval\n",
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "inputs = [\n",
    "    \"Help me find a 3 bedroom apartment with a new bathroom and high ceilings.\",\n",
    "    \"Help me find an apartment that has a washer, dryer, front porch, is 600-700 a month, and has air conditioning.\",\n",
    "    \"Are there any apartments with 8 bedrooms and hard wood floors?\"\n",
    "]\n",
    "\n",
    "expected_outputs = [\n",
    "    \"12 N Congress St Apt 1, 12 N Congress St Apt 4, 12 N Congress St Apt 5\",\n",
    "    \"20 N Congress St Apt 1\",\n",
    "    \"36 W State St\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# Running through all tests to evaluate accuracy\n",
    "tests = []\n",
    "for testIndex in range(len(inputs)):\n",
    "    # Getting response from model\n",
    "    response = rag_chain.invoke({\"input\": inputs[testIndex]})\n",
    "    currentContext = [str(i) for i in response[\"context\"]]\n",
    "    # print(response[\"answer\"])\n",
    "    test_case = LLMTestCase(\n",
    "        input=inputs[0],\n",
    "        expected_output=expected_outputs[testIndex],\n",
    "        actual_output=\" \".join([i.metadata[\"title\"] for i in response[\"context\"]]),\n",
    "        retrieval_context=currentContext\n",
    "    )\n",
    "\n",
    "    tests.append(test_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf52aaee-1714-42ba-8d16-70559f10a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:06,  6.92s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:14, 14.00s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:10, 10.49s/test case]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Metrics: Answer Relevancy (score: 0.0, threshold: 0.5, strict: False, error: None) failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43massert_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mAnswerRelevancyMetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/KleinPennySearch/KleinPennyRAGBot/myenv/lib/python3.9/site-packages/deepeval/evaluate.py:995\u001b[0m, in \u001b[0;36massert_test\u001b[0;34m(test_case, metrics, run_async)\u001b[0m\n\u001b[1;32m    987\u001b[0m             failed_metrics_data\u001b[38;5;241m.\u001b[39mappend(metric_data)\n\u001b[1;32m    989\u001b[0m failed_metrics_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    990\u001b[0m     [\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, strict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mstrict_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metrics_data \u001b[38;5;129;01min\u001b[39;00m failed_metrics_data\n\u001b[1;32m    993\u001b[0m     ]\n\u001b[1;32m    994\u001b[0m )\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed_metrics_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Metrics: Answer Relevancy (score: 0.0, threshold: 0.5, strict: False, error: None) failed."
     ]
    }
   ],
   "source": [
    "# Answer Relevancy -- fails on 3\n",
    "for test in tests:\n",
    "    assert_test(test, [AnswerRelevancyMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c85d6b3-40f5-4c71-ac25-d99097c26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.metrics import FaithfulnessMetric\n",
    "from deepeval.metrics import ContextualRecallMetric\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3933a-afe5-4a68-a7ef-c9aee6b8d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faithfulness -- all pass\n",
    "for test in tests:\n",
    "    assert_test(test, [FaithfulnessMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2c67d40-c1b1-40b3-9f16-fcd5461ecbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:07,  7.26s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:05,  5.09s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:02,  2.90s/test case]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Metrics: Contextual Recall (score: 0.0, threshold: 0.5, strict: False, error: None) failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Contextual Recall\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43massert_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mContextualRecallMetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/KleinPennySearch/KleinPennyRAGBot/myenv/lib/python3.9/site-packages/deepeval/evaluate.py:995\u001b[0m, in \u001b[0;36massert_test\u001b[0;34m(test_case, metrics, run_async)\u001b[0m\n\u001b[1;32m    987\u001b[0m             failed_metrics_data\u001b[38;5;241m.\u001b[39mappend(metric_data)\n\u001b[1;32m    989\u001b[0m failed_metrics_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    990\u001b[0m     [\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, strict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mstrict_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metrics_data \u001b[38;5;129;01min\u001b[39;00m failed_metrics_data\n\u001b[1;32m    993\u001b[0m     ]\n\u001b[1;32m    994\u001b[0m )\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed_metrics_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Metrics: Contextual Recall (score: 0.0, threshold: 0.5, strict: False, error: None) failed."
     ]
    }
   ],
   "source": [
    "# Contextual Recall -- fails on 3rd\n",
    "for test in tests:\n",
    "    assert_test(test, [ContextualRecallMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c453735-0543-4bc4-8cca-2f98a57dc187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:05,  5.83s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:07,  7.04s/test case]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Metrics: Contextual Precision (score: 0.3333333333333333, threshold: 0.4, strict: False, error: None) failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Contextual Precisison -- all pass\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43massert_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mContextualPrecisionMetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/KleinPennySearch/KleinPennyRAGBot/myenv/lib/python3.9/site-packages/deepeval/evaluate.py:995\u001b[0m, in \u001b[0;36massert_test\u001b[0;34m(test_case, metrics, run_async)\u001b[0m\n\u001b[1;32m    987\u001b[0m             failed_metrics_data\u001b[38;5;241m.\u001b[39mappend(metric_data)\n\u001b[1;32m    989\u001b[0m failed_metrics_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    990\u001b[0m     [\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, strict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mstrict_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metrics_data \u001b[38;5;129;01min\u001b[39;00m failed_metrics_data\n\u001b[1;32m    993\u001b[0m     ]\n\u001b[1;32m    994\u001b[0m )\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed_metrics_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Metrics: Contextual Precision (score: 0.3333333333333333, threshold: 0.4, strict: False, error: None) failed."
     ]
    }
   ],
   "source": [
    "# Contextual Precisison -- fail\n",
    "for test in tests:\n",
    "    assert_test(test, [ContextualPrecisionMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b87e5bd-fc2c-4d07-96b0-26909db399f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:31, 31.04s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |█████████████████████████████|100% (1/1) [Time Taken: 00:38, 38.88s/test case]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Metrics: Contextual Relevancy (score: 0.18604651162790697, threshold: 0.5, strict: False, error: None) failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ContextualRelevancyMetric\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43massert_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mContextualRelevancyMetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/KleinPennySearch/KleinPennyRAGBot/myenv/lib/python3.9/site-packages/deepeval/evaluate.py:995\u001b[0m, in \u001b[0;36massert_test\u001b[0;34m(test_case, metrics, run_async)\u001b[0m\n\u001b[1;32m    987\u001b[0m             failed_metrics_data\u001b[38;5;241m.\u001b[39mappend(metric_data)\n\u001b[1;32m    989\u001b[0m failed_metrics_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    990\u001b[0m     [\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, threshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, strict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39mstrict_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_data\u001b[38;5;241m.\u001b[39merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metrics_data \u001b[38;5;129;01min\u001b[39;00m failed_metrics_data\n\u001b[1;32m    993\u001b[0m     ]\n\u001b[1;32m    994\u001b[0m )\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailed_metrics_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Metrics: Contextual Relevancy (score: 0.18604651162790697, threshold: 0.5, strict: False, error: None) failed."
     ]
    }
   ],
   "source": [
    "# ContextualRelevancyMetric -- fail on 2\n",
    "for test in tests:\n",
    "    assert_test(test, [ContextualRelevancyMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d28ec7-7b30-4650-b87c-488c36b08e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
